# -*- coding: utf-8 -*-
"""Credit Analytics.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_J7co3PpyE4KGlFak_7XhUwmD8n3o5hJ

##**Loading the Required Python Libraries**##
"""

#Run all the required Libraries

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

"""##**Connecting to Google Drive**##

Because the google collab jupyter notebook is volatile and widely used, there is need to conect the note to google collab for ease of data access.
"""

from google.colab import drive # The code reading the folder containing all the images in the zip folders on google drive

drive.mount("/content/gdrive")

"""##**Reading the Data**##

The code below assist to assign the data from the temporary gdrive created above to a variable called "Data" below.
"""

Data = pd.read_csv('/content/gdrive/MyDrive/PPS 7-5-2023.csv') #Read Out the Data

"""##**Exploring the Data**##"""

Data.head(3) #Call out the first three rows

Data.tail(3) #Call the last three lines

Data['username'].count() #Count of all the total Data.meaning count of all rows in the datasets

Data.describe() # Showing the quick summary of the Credit datasets

Data.dtypes #Showing the all the features of the credit datasets. Only few of these feautures are used for exploratory and machine learning.

# Showing the Distribution of Loan status with a bar chart

Groupby_Data = Data.groupby('repaymentStatus')['amount'].sum().reset_index()

sns.barplot(x= 'repaymentStatus', y = 'amount', data=Groupby_Data)
plt.title('Distribution of Active VS Completed Loans')
plt.xlabel('Loan Status')
plt.ylabel('Loan Values(10Billions)')

Data.isnull().sum() #There is no single null value in the datasets

# Change the N/A values to 0. The N/A are ordinarily supose to be zeros based on the knowlege of the datasets
Data['balance_available'] = pd.to_numeric(Data['balance_available'], errors='coerce').fillna(0)
Data['outstanding_balance'] = pd.to_numeric(Data['outstanding_balance'], errors='coerce').fillna(0)

Data.describe()

#Checking the levels. Levels means the values of data in tenure column
Data['tenure'].unique()

#The level seen above needs to be cleaned and the cleaning is dine in this code chunk

Data['tenure'] = Data['tenure'].str.strip().replace({'1 Days': '1 Day',
                                                     '2 Days': '1 Day',
                                                     '1 days':'1 Day',
                                                     '14 Days':'1 Day', 
                                                     '3 days': '3 Days',
                                                     '5 days': '5 Days',
                                                     '7 days': '7 Days',
                                                     '15 days':'BNPL'})
Data['tenure'].unique()

"""##Quick summary of the Tenure and Disbursed Amounts##
This shows disbursement from inception till date.
"""

#A Quick summary of tenure and disbursed amounts from inception till date.
GroupTenure = Data.groupby('tenure')['amount'].sum().reset_index()
GroupTenure

"""##Bar Chart of Disbusement by Tenure##"""

sns.barplot(x= 'tenure', y= 'amount', data=GroupTenure)
plt.title('Disbursement By Tenures')
plt.xlabel('Tenures')
plt.ylabel('Amounts')
plt.show()

"""##Analysing Date and Extracting the Year, Month and Day from Date Format##"""

Data['created_date'] = pd.DatetimeIndex(Data['created_date'])
Data['duedate'] = pd.DatetimeIndex(Data['duedate'])
Data['Year'] = Data['created_date'].dt.year
Data['Month'] = Data['created_date'].dt.month
Data['Day'] = Data['created_date'].dt.day

#Data['DPD']= Data['duedate']-Data['created_date']
#Data['DPD'].tail()

Data.head(2)

"""##Summary of Data by Year and Disbursement Amounts##"""

GroupYear = Data.groupby('Year')['amount'].sum().reset_index()
GroupYear

"""##Bar Chart for Disbursment and Years of Disbursement##"""

sns.barplot(x= 'Year', y= 'amount', data=GroupYear)
plt.title('Yearly Disbursement')
plt.xlabel('Years')
plt.ylabel('Amounts Disbursed')
plt.show()

"""##Extracting only Disbursement from Inception to April, 2023##"""

DueLoans = Data[Data['duedate']<= '2023-04-30']
DueLoans.head(3) #First three rows in the datasets.

"""##Quick Summary of the Important Features of the Credit Data##"""

GroupByDueloans = DueLoans.groupby('Year').agg({'loanID': 'count',
                                                'username': 'nunique',
                                                'amount': 'sum',
                                                 'repaymentAmount': 'sum',
                                                 'outstanding_balance': 'sum',
                                                 'totalPaid': 'sum',
                                                 }).reset_index()
GroupByDueloans

"""##Calculating the Default Rates for Each Year##"""

GroupByDueloans['DefaultRates'] = (GroupByDueloans['outstanding_balance']/GroupByDueloans['repaymentAmount'])*100
GroupByDueloans

"""##Plot a Box Plot for Disbursed Loans and Repayment Status##
This chart shows a quick summary of the credit data from inception til April, 2023. It shows the min , max, mean, median, first percentile, third percentile with outliers of the disbursed amounts.
"""

sns.boxplot(x ='amount', y= 'repaymentStatus', data= DueLoans )
plt.title('Disbursement VS RepaymentStatus BoxPlot')
plt.xlabel('Disbursement Values')
plt.ylabel('LoanStatus')

"""##Histogram of the Disbursed Amounts##

The histogram shows that the data is positively skewed. It means that most of the credit advanced are within the lower loan band. Between 1000 to about 35,000 naira.
"""

sns.histplot(x ='amount', data= DueLoans )
plt.title('Distribution of DisbursedAmounts')
plt.xlabel('Disbursement Values')
plt.ylabel('Volumes')

"""##**Analysing the 2023 Credit Data**##

The focus here is only on the loan advanced in 2023. 2023 credit data generated are dissected and analysed.
"""

# The code extracting the 2023 data.
Data2023 = Data[Data['Year'] == 2023]
Data2023.head(2) # Showing the first two rows of the credit data.

"""##Quick Summary of 2023 Data##

The summary shows the loan advanced in each month, total loan uptakes, unique count of agents, loan amount advanced, repaymentamounts, outstanding amount, total loan paid.
"""

GroupBy2023 = Data2023.groupby('Month').agg({'loanID':'count',
                                             'username':'nunique',
                                         'amount':'sum',
                                         'repaymentAmount': 'sum',
                                         'outstanding_balance': 'sum',
                                         'totalPaid':'sum'}).reset_index()
GroupBy2023

"""##Calculating the Default Rates and Revenues##

This session extracted the default rates and revenue of all loans advanced Year to date YTD in addition to the Averaage Loan Size(ALS).
"""

#Calculating the default rates, Revenue and Average loan sizes in each  month
GroupBy2023['DefaultRates2023'] = (GroupBy2023['outstanding_balance']/GroupBy2023['repaymentAmount'])*100
GroupBy2023['ALS'] = GroupBy2023['amount']/GroupBy2023['loanID']
GroupBy2023['Revenue'] = GroupBy2023['repaymentAmount']-GroupBy2023['amount']
GroupBy2023
#GroupBy2023['Revenue'].sum()

"""##Extracting the Important Parameters##

This session extracted the important credit metrics for credit evaluation. However, it is evidenced that the default rate for April is extremly higher than the other month and the AVL continues to decline each month. This is due to the introduction of the lower loan sizes in two weeks ago. There are also some intentional efforts to reduce the default rates from the collections point to the engineering point. 
"""

Disbursement_2023 = GroupBy2023[['Month','amount','DefaultRates2023','ALS']]
Disbursement_2023

"""##Correlation of the Major Credit Metrics##

The important metrics to consider here is the loan disbursed amount, ALS, default rates and Month.The heatmap belows shows some positive , negative, strong and weak correltion for some of these metrics as seen below.
"""

Correla = Disbursement_2023.corr()
sns.heatmap(Correla,xticklabels = Correla.columns, yticklabels=Correla.columns, annot = True)

"""##Line Chart of the YTD Disbursement##"""

#The code for ploting a line Chart.
sns.lineplot(x = 'Month', y = 'amount', data=Disbursement_2023)
plt.xticks(range(1, 6, 1))

# add labels and title
plt.xlabel('Months')
plt.ylabel('Disbursement_Values')
plt.title('2023 Disbursement')

# show the plot
plt.show()

"""##Considering the Month and Defaultrates##"""

GroupBy2023[['Month', 'DefaultRates2023']]

"""## Bar Chart of Default Rates By Months##"""

sns.barplot(x= 'Month', y = 'DefaultRates2023', data= GroupBy2023[['Month', 'DefaultRates2023']])
plt.title('Default_Rates By Months')

"""##Box Plot of the Amount Disbursed##

The box shows a quik summary of the important measues like min, max and e.t.c as seen above for YTD only.
"""

sns.boxplot(x ='amount', y= 'repaymentStatus', data= Data2023 )
plt.title('Disbursement VS RepaymentStatus BoxPlot')
plt.xlabel('Disbursement Values')
plt.ylabel('LoanStatus')

"""##Histogram of Disbursed Amount YTD##"""

sns.histplot(x ='amount', data= Data2023 )
plt.title('Distribution_DisbursedAmounts 2023')
plt.xlabel('DisbursementValues')
plt.ylabel('Volumes')

"""##Quick Summary by Tenure##"""

GroupBy2023Tenure = Data2023.groupby('tenure')['amount','repaymentAmount', 'outstanding_balance','totalPaid'].sum().reset_index()
GroupBy2023Tenure

"""##Calculation of Default Rates by Tenures##"""

GroupBy2023Tenure['DefaultRates'] = (GroupBy2023Tenure['outstanding_balance']/GroupBy2023Tenure['repaymentAmount'])*100
GroupBy2023Tenure

GroupBy2023Tenure[['tenure','DefaultRates']]

"""##Bar Chart of the Default by Tenure##"""

sns.barplot(x = 'tenure', y = 'DefaultRates', data= GroupBy2023Tenure[['tenure','DefaultRates']])
plt.title('DefaultRates VS Tenure')



"""##**Recovery Logic Performance**##

This estimated the balances in the agents wallets at the time of this report.These are balances the recovery logic is not able to debit on the defaulters  agents wallets at the time of this analysis.
"""

Due2023 = Data2023[Data2023['duedate'] <= '2023-05-07']
Due2023['repaymentStatus'] =='active'

"""##Filter the Active Due Loans Alone##"""

ActiveLoans = Due2023[Due2023['repaymentStatus'] =='active']
ActiveLoans.tail(3)

#Summary of the Balances in the agents wallets per Month (YTD)
GroupByDue2023 = ActiveLoans.groupby('Month').agg({'loanID':'count',
                                             'username':'nunique',
                                         'amount':'sum',
                                         'repaymentAmount': 'sum',
                                         'outstanding_balance': 'sum',
                                         'totalPaid':'sum',
                                         'balance_available': 'sum'}).reset_index()

GroupByDue2023

GroupByDue2023['balance_available'].sum()

"""##DownLoad The Balances on Agents Wallets##

This session write the balances in tbe agents wallets in each month YTD to csv file. This is neccesary for escalation to  the credit developers and or further analysis.


"""

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Set the file path and name for the CSV file
file_path = '/content/drive/MyDrive/ActiveLoans.csv'

# Save the DataFrame as a CSV file
ActiveLoans.to_csv(file_path, index=False)

# Download the CSV file to local machine
from google.colab import files
files.download(file_path)

"""##**Machine Learning on Credit Data**##

In this session, we will be writing different machine learning algorithm to predict PPS or BNPL defaulters and those with good credit standing. We will me using both neural network models and Non-neural network models in this session.

##Reading the Agents New Data Including their Bio Data ##

In the EDA above, there are no additional information to the agents credit data.It is therefore imperative to consider this information to allow different machine leraning models to learn from it and make better predictions.

##Limitations##

There are other important features that are not available in this analysis. They are ages of agents, tenancy status, shop or store types, marital status, and education levels. 

##Available Features in the Models are:##

 'amount','interest', 'purpose', 'tenure', 'debit_interest', 'feeees','repaymentAmount', 'totalPaid', 'outstanding_balance',
'balance_available', 'repaymentStatus', ', 'created_date', 'Year', 'Month', 'Day', 'States', 'LGA','Regions', 'Gender', 'Channel', 'Pertners', 'Kyc_Types'
"""

#Reading the PPS Data with Agents Bio Data
Bio_Data = pd.read_csv('/content/drive/MyDrive/PPS and BioData Information.csv') #Read Out the Data
Bio_Data.tail(3)

"""##**Data Preprosessing**##

Data preprosessing deals with data wrangling, and encoding the categorical features to prepare them for machine learnings.
"""

Bio_Data.columns

Bio_Data.dtypes

"""##Drop Irrelevant Variables##

Irrelevant variables are variables that are not useful for the model. They are as seen below:
"""

Bio_Data = Bio_Data.drop(['duedate',
                          'created_date',
                          'completed_date', 
                          'updated_Date',
                          'request_id', 
                          'agent_id',
                          'username',
                          'loanID',
                          'id',
                          'purpose'], axis=1)

"""##Preview the Important Features of the Datasets##"""

Bio_Data.tail(2)

Bio_Data.dtypes

Bio_Data['Gender'].unique()

Bio_Data['Gender'] = Bio_Data['Gender'].str.strip().replace({'F': 'Female',
                                                     'M': 'Male',
                                                     'Others':'Female'})

Bio_Data['tenure'] = Bio_Data['tenure'].str.strip().replace({'1 Days': '1 Day',
                                                     '2 Days': '1 Day',
                                                     '1 days':'1 Day',
                                                     '14 Days':'1 Day', 
                                                     '3 days': '3 Days',
                                                     '5 days': '5 Days',
                                                     '7 days': '7 Days',
                                                     '15 days':'BNPL'})
Bio_Data['tenure'].unique()

Bio_Data['States'] = Bio_Data['States'].str.strip().replace({'Federal Capital Territory': 'FCT',
                                                             'Others': 'Lagos'})
Bio_Data['States'].unique()

Bio_Data['Regions'] = Bio_Data['Regions'].str.strip().replace({'northwest 1': 'Northwest 1',
                                                     'Others': 'lagos I',
                                                     'Lagos I': 'lagos I'})
Bio_Data['Regions'].unique()

Bio_Data['Gender'].unique()

Bio_Data['Channel'] = Bio_Data['Channel'].str.strip().replace({'Others': 'POS'})
Bio_Data['Channel'].unique()

Bio_Data['Pertners'] = Bio_Data['Pertners'].str.strip().replace({'Others': 'Baxi Pro'})
Bio_Data['Pertners'].unique()

Bio_Data['Kyc_Types'] = Bio_Data['Kyc_Types'].str.strip().replace({'Others': 'Level 15'})
Bio_Data['Kyc_Types'].unique()

Bio_Data = Bio_Data.rename(columns = {'Pertners': 'Partners'})
Bio_Data.columns

"""##Data Preprocessing##

The new data needs to be preprocessed to be ready for machine learning. Here are the difference preprocessing stages below:
"""

#Encoding the columns
le = LabelEncoder()
Bio_Data['tenure'] = le.fit_transform(Bio_Data['tenure'])
Bio_Data['repaymentStatus'] = le.fit_transform(Bio_Data['repaymentStatus'])
Bio_Data['Channel'] = le.fit_transform(Bio_Data['Channel'])
Bio_Data['Gender'] = le.fit_transform(Bio_Data['Gender'])
Bio_Data['Partners'] = le.fit_transform(Bio_Data['Partners'])
Bio_Data['Regions'] = le.fit_transform(Bio_Data['Regions'])
Bio_Data['States'] = le.fit_transform(Bio_Data['States'])
Bio_Data['Kyc_Types'] = le.fit_transform(Bio_Data['Kyc_Types'])
Bio_Data['LGA']= le.fit_transform(Bio_Data['LGA'])

Bio_Data.dtypes

Bio_Data.tail(3)

Bio_Data.nunique()

"""##**Correleations**##

The correlation is a measure that shows the relationship between all the important features considered in the model. The closer it is to 1 or -1, the higher the relationship between the variables. -1 shows negative relationship however.
"""

Correl = Bio_Data.corr()
sns.set(rc={'figure.figsize':(20,8)})
sns.heatmap(Correl,xticklabels = Correl.columns, yticklabels=Correl.columns, annot = True)

"""##Loading the important Libraries for Model Evaluation and Data Spliting ##

Models are built and evaluated based on certaain metrics. These metrics are recall, precisions, accuracy and auc. They are further explained as: 

**Accuracy:** percentage of correct predictions

**Recall:** ratio of true positives to actual positives

**Precision:** ratio of true positives to predicted positives

**AUC:** measure of a model's ability to distinguish between positive and negative classes.


"""

from sklearn.model_selection import train_test_split #
from sklearn import svm
from sklearn.model_selection import StratifiedKFold
from sklearn.model_selection import cross_val_score
from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score,roc_auc_score

Active_Loans = Bio_Data[Bio_Data['repaymentStatus'] == 0]
#Active_Loans['repaymentStatus'].count()

Completed_Loans = Bio_Data[Bio_Data['repaymentStatus'] == 1]
Completed_Loans['repaymentAmount'].count()

import random #. Loading the Random selection library

PPS_DataSample = Bio_Data.sample(n=20000, random_state=random.seed())
PPS_DataSample.dtypes

PPS_DataSample.tail(3)

Class = PPS_DataSample['repaymentStatus']
Class.shape

PPS_Features = PPS_DataSample.drop('repaymentStatus', axis=1)
PPS_Features.tail(3)

"""##**Split Credit Data**##

Here, the code below split the credit data into two different sets. The training datasets and the testing data sets. The soliting ratio is 80: 20. 80% is the used to train the obverall data and the 20% of the data is used to test for the model accuracy. However, there are other sets of data that are different from the training and testing test that are used to validate the model if it performs better.
"""

#Spliting the PPS_BioData datasets into training and testing.
X_train, X_test, y_train, y_test = train_test_split(PPS_Features, Class, stratify= Class,test_size=0.2)
print('Shapes XTrain:', X_train.shape) #Print the shape of the x-train
print('Shapes XTest:', X_test.shape)

from sklearn.model_selection import StratifiedKFold

#CV = StratifiedKFold(n_splits=5) # Setting the cross validation to 5 using a Startified sampling method.
#CV.get_n_splits(Bio_Data, Class) # fitiing the 5 fold cross validation function
#print(CV)



#np.random.seed(123) # set a seed to allow the model to be reproducible
#SVM_Model = svm.SVC(kernel= 'linear', probability=True) #Calling a SVM linear Model. There are other option like polynomial and Support vector regression and others.
#cv_scores = cross_val_score(SVM_Model, X_train, y_train)

#SVM_Model.fit(X_train, y_train)

#y_pred = SVM_Model.predict(X_test)

#accuracy = accuracy_score(y_test, y_pred)
#precision = precision_score(y_test, y_pred)
#recall = recall_score(y_test, y_pred)
#auc = roc_auc_score(y_test, svm.predict_proba(X_test)[:,1])
#print('Accuracy', accuracy)
#print('recall', recall)
#print('auc', auc)
#print('precision', precision)

#print('SVM Accuracy Levels : ', cross_val_score(SVM_Model, X_test , y_test, cv=CV, scoring = 'accuracy'))
#print('SVM Recalls :', cross_val_score(SVM_Model, X_test , y_test, cv=CV, scoring = 'recall'))
#print('SVM Precisions: ',cross_val_score(SVM_Model, X_test , y_test, cv=CV, scoring = 'precision'))
#print(' SVM Fscores: ',cross_val_score(SVM_Model, X_test , y_test, cv=CV, scoring = 'f1'))

"""##**Builidng and Evaluating  a Logistic Regression Model**##"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix
model2 = LogisticRegression()

# fit model
model2.fit(X_train, y_train)

# predict on test set
y_pred1 = model2.predict(X_test)
y_prob1 = model2.predict_proba(X_test)[:, 1]

# evaluation metrics
print('Accuracy:', accuracy_score(y_test, y_pred1))
print('Precision:', precision_score(y_test, y_pred1))
print('Recall:', recall_score(y_test, y_pred1))
print('F1 score:', f1_score(y_test, y_pred1))
print('ROC AUC score:', roc_auc_score(y_test, y_prob1))
#Confusion Matrix of the Model.
print('Confusion matrix:\n', confusion_matrix(y_test, y_pred1))

"""##Plot the AUC of the Logistic Model##"""

from sklearn.metrics import roc_curve, auc
fpr, tpr, thresholds = roc_curve(y_test, y_pred1)
roc_auc = auc(fpr, tpr)

plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic(ROC) Curve')
plt.legend(loc="lower right")
plt.show()

"""##Plot the Confusion Matrix of Logistic Regression Model##"""

import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix

model2 = LogisticRegression()
model2.fit(X_train, y_train)

y_pred1 = model2.predict(X_test)

# Generate confusion matrix
conf_mat = confusion_matrix(y_test, y_pred1)

# Plot the confusion matrix
plt.imshow(conf_mat, cmap='Greens', interpolation='None')
plt.colorbar()

plt.xticks([0, 1], ['Class 0', 'Class 1'])
plt.yticks([0, 1], ['Class 0', 'Class 1'])
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')

for i in range(conf_mat.shape[0]):
    for j in range(conf_mat.shape[1]):
        plt.annotate(str(conf_mat[i][j]), xy=(j, i), ha='center', va='center')

plt.show()

"""##Random Selection to Revalidate the Model Metrics##

A new set of 500 credit  data is selected to retest the accuracy of the model from the overall datasets. These are random selections 
"""

PPS_Val= Bio_Data.sample(n=500, random_state=random.seed(222))
PPS_Val.count()

Negative = PPS_Val[PPS_Val['repaymentStatus']==0]
Negative['repaymentStatus'].count()

y_test2 = PPS_Val['repaymentStatus']
y_test2



PPS_Val = PPS_Val.drop('repaymentStatus', axis = 1)

PPS_Val.dtypes

#predict on test set
y_pred2 = model2.predict(PPS_Val)
y_prob2 = model2.predict_proba(PPS_Val)[:, 1]

# evaluation metrics
print('Accuracy:', accuracy_score(y_test2, y_pred2))
print('Precision:', precision_score(y_test2, y_pred2))
print('Recall:', recall_score(y_test2, y_pred2))
print('F1 score:', f1_score(y_test2, y_pred2))
print('ROC AUC score:', roc_auc_score(y_test2, y_prob2))
print('Confusion matrix:\n', confusion_matrix(y_test2, y_pred2))

"""##Comments##

The revalidated model leaves a very good model metrics results. This means the model had predicted well on the test data and validation data (500 observations)

##AUC Curve for the Revalidated Data##

The curve shows that the the model has 89% probability of predicting well on the revalidated 500 data. This goes for any other agents data that goes with the model. In Summary, 9 out of 10 customers are predicted correctly.
"""

fpr, tpr, thresholds = roc_curve(y_test2, y_pred2)
roc_auc = auc(fpr, tpr)

plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic(ROC) Curve')
plt.legend(loc="lower right")
plt.show()

"""##Confusion Matrix: Revalidated Data##
This shows how the model is predicting correctly and wrongly on the good and defaulting customers.
"""

conf_mat2 = confusion_matrix(y_test2, y_pred2)

# Plot the confusion matrix
plt.imshow(conf_mat2, cmap='Reds', interpolation='None')
plt.colorbar()

plt.xticks([0, 1], ['Class 0', 'Class 1'])
plt.yticks([0, 1], ['Class 0', 'Class 1'])
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')

for i in range(conf_mat2.shape[0]):
    for j in range(conf_mat2.shape[1]):
        plt.annotate(str(conf_mat2[i][j]), xy=(j, i), ha='center', va='center')

"""##Writing the Bio_Data into a CSV File##"""

# Set the file path and name for the CSV file
file_path = '/content/drive/MyDrive/Bio_Data.csv'

# Save the DataFrame as a CSV file
Bio_Data.to_csv(file_path, index=False)

# Download the CSV file to local machine
from google.colab import files
files.download(file_path)

"""##Reading a New Datasets for Another Validation##

Here, 40 records were reselected. At this level, we are intentional about the class balance. The defaulters are 20 and agents with good credit records are 20. This gives a fair prediction by the model. The accuracy is also obtained at this level for comparison.
"""

Data2 = pd.read_excel('/content/drive/MyDrive/Test2Data.xlsx') 
Data2.tail(3)

y_test3 = Data2['repaymentStatus']
y_test3.shape

ValData3 = Data2.drop('repaymentStatus', axis=1)
ValData3.count()

"""##Predict and Evaluate the 40 Observations##"""

# predict on test set
y_pred3 = model2.predict(ValData3)
y_prob3 = model2.predict_proba(ValData3)[:, 1]

# evaluation metrics
print('Accuracy:', accuracy_score(y_test3, y_pred3))
print('Precision:', precision_score(y_test3, y_pred3))
print('Recall:', recall_score(y_test3, y_pred3))
print('F1 score:', f1_score(y_test3, y_pred3))
print('ROC AUC score:', roc_auc_score(y_test3, y_prob3))
print('Confusion matrix:\n', confusion_matrix(y_test3, y_pred3))

"""##Comments##

It is evidenced that the model prediction is not bad still. The model only has 4 wrong predictions out of 40. 36 were predicted correctly. the AUC However, increased to 96%. It means it almost predicts all agents default behaviour corectly.

##AUC and the Confusion Matrix for 40 Observation##
"""

conf_mat3 = confusion_matrix(y_test3, y_pred3)

# Plot the confusion matrix
plt.imshow(conf_mat3, cmap='Reds', interpolation='None')
plt.colorbar()

plt.xticks([0, 1], ['Class 0', 'Class 1'])
plt.yticks([0, 1], ['Class 0', 'Class 1'])
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')

for i in range(conf_mat3.shape[0]):
    for j in range(conf_mat3.shape[1]):
        plt.annotate(str(conf_mat3[i][j]), xy=(j, i), ha='center', va='center')

fpr, tpr, thresholds = roc_curve(y_test3, y_pred3)
roc_auc = auc(fpr, tpr)

plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic(ROC) Curve')
plt.legend(loc="lower right")
plt.show()

"""##**Building a CNN Model**##

The Convolutionary Neural Network model is the state of the art machine learning model and it belongs to a mother of a neral networks. We will be building a neural nework to train and test the PPS data for better predictions.
"""

# Reshape data for CNN model

import tensorflow as tf
from sklearn.model_selection import train_test_split
from keras.models import Sequential
from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout

# Reshape data for CNN model
X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)
X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)

# Create CNN model
modelcnn = Sequential()
modelcnn.add(Conv1D(32, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))
modelcnn.add(MaxPooling1D(pool_size=2))
modelcnn.add(Flatten())
modelcnn.add(Dense(64, activation='relu'))
modelcnn.add(Dropout(0.25))
modelcnn.add(Dense(1, activation='sigmoid'))

# Compile model
# Compile model
modelcnn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

# Fit model
history = modelcnn.fit(X_train, y_train, batch_size=64, epochs=10, verbose=1, validation_data=(X_test, y_test))

# Evaluate model on test data
y_pred4 = modelcnn.predict(X_test)
y_pred_classes = (y_pred4 > 0.5).astype('int32')

accuracy = accuracy_score(y_test, y_pred_classes)
precision = precision_score(y_test, y_pred_classes)
recall = recall_score(y_test, y_pred_classes)
auc = roc_auc_score(y_test, y_pred4)

print('Accuracy:', accuracy)
print('Precision:', precision)
print('Recall:', recall)
print('AUC:', auc)

"""##Comments##

The Convolution Neural Networks , which works on different neurons before decision are made is better than Logistic Model. Evidence seen above, The accuracy level increased considerably and the AUC jumped to 98%.

##Plot the Confusion Matric and the AUC FOR CNN##
"""

from sklearn.metrics import confusion_matrix

# Compute confusion matrix
y_test_binary = (y_test >= 0.5).astype(int)
y_pred_classes = (y_pred4 >= 0.5).astype(int)
conf_mat4 = confusion_matrix(y_test_binary, y_pred_classes)

# Plot confusion matrix
plt.imshow(conf_mat4, cmap='Reds', interpolation='None')
plt.colorbar()

plt.xticks([0, 1], ['Class 0', 'Class 1'])
plt.yticks([0, 1], ['Class 0', 'Class 1'])
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')

for i in range(conf_mat4.shape[0]):
    for j in range(conf_mat4.shape[1]):
        plt.annotate(str(conf_mat4[i][j]), xy=(j, i), ha='center', va='center')

plt.show()

"""##Using CNN Model to Predict A new set of Data##

This is a compepletly different data of balanced class. This will show the quality of decisions CNN model is making on the new credit application.
"""

# Evaluate model on test data

y_prob5 = modelcnn.predict(ValData3)
y_pred5 = (y_prob5 > 0.5).astype(int)

# evaluation metrics
print('Accuracy:', accuracy_score(y_test3, y_pred5))
print('Precision:', precision_score(y_test3, y_pred5))
print('Recall:', recall_score(y_test3, y_pred5))
print('F1 score:', f1_score(y_test3, y_pred5))
print('ROC AUC score:', roc_auc_score(y_test3, y_prob5))
print('Confusion matrix:\n', confusion_matrix(y_test3, y_pred5))

# obtain the confusion matrix
conf_mat = confusion_matrix(y_test3, y_pred5)

# plot the confusion matrix
sns.heatmap(conf_mat, annot=True, cmap='Blues', fmt='g')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix on Validation Data')
plt.show()

# compute the false positive rate, true positive rate, and thresholds
fpr, tpr, thresholds = roc_curve(y_test3, y_pred5)

# compute the area under the curve
roc_auc = roc_auc_score(y_test3, y_pred5)

# plot the ROC curve
plt.plot(fpr, tpr, label='ROC curve (AUC = %0.2f)' % roc_auc, color='b')
plt.plot([0, 1], [0, 1], 'k--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver operating characteristic (ROC): Validation Data')
plt.legend(loc='lower right')
plt.show()

"""##Comments##

From the result of the Model, The area under the curve AUC is 92% for CNN which is better than the one obtained in Logistics regression Model. CNN prediction is given better consoderation and likely deployed to live considering its evaluation metrics.
"""

